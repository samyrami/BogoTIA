import pandas as pd
import streamlit as st
import os
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain.schema import HumanMessage, SystemMessage
from langchain.callbacks.base import BaseCallbackHandler
from html_template import logo
from langchain.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.chains import ConversationalRetrievalChain
from langchain.memory import ConversationBufferMemory
import re

# Load environment variables
load_dotenv()

# Get API key from environment variables
API_KEY = os.getenv("OPENAI_API_KEY")
if API_KEY is None:
    st.error("Error: OPENAI_API_KEY not found in environment variables")
    st.stop()
    
st.set_page_config(page_title="BogotAI", layout="centered", menu_items= {
        'Get Help': 'https://www.extremelycoolapp.com/help',
        'Report a bug': "https://www.extremelycoolapp.com/bug",
        'About': "# This is a header. This is an *extremely* cool app!"
    })

class MunicipalDocumentProcessor:
    def __init__(self, pdf_directory="data", index_directory="faiss_index"):
        self.pdf_directory = pdf_directory
        self.index_directory = index_directory
        self.embeddings = OpenAIEmbeddings()
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200,
            length_function=len
        )
        
        os.makedirs(self.pdf_directory, exist_ok=True)
        os.makedirs(self.index_directory, exist_ok=True)

    def load_vector_store(self):
        """Carga el vector store existente"""
        index_path = os.path.join(self.index_directory, "index.faiss")
        try:
            if os.path.exists(index_path):
                return FAISS.load_local(
                    self.index_directory, 
                    self.embeddings,
                    allow_dangerous_deserialization=True
                )
            return None
        except Exception as e:
            st.error(f"Error cargando vector store: {str(e)}")
            return None

    def process_documents(self):
        """Procesa los documentos PDF y crea el vector store"""
        try:
            pdf_files = [f for f in os.listdir(self.pdf_directory) if f.endswith('.pdf')]
            if not pdf_files:
                st.warning("No se encontraron archivos PDF en el directorio data.")
                return None

            documents = []
            successful_files = []
            failed_files = []
            
            for pdf_file in pdf_files:
                try:
                    file_path = os.path.join(self.pdf_directory, pdf_file)
                    
                    with open(file_path, 'rb') as file:
                        header = file.read(5)
                        if header != b'%PDF-':
                            failed_files.append((pdf_file, "Encabezado PDF inv√°lido"))
                            continue
                    
                    loader = PyPDFLoader(file_path)
                    doc_pages = loader.load()
                    
                    if doc_pages:
                        documents.extend(doc_pages)
                        successful_files.append(pdf_file)
                        st.success(f"‚úÖ Procesado exitosamente: {pdf_file} ({len(doc_pages)} p√°ginas)")
                    else:
                        failed_files.append((pdf_file, "No se pudo extraer contenido"))
                
                except Exception as e:
                    failed_files.append((pdf_file, str(e)))
                    continue

            st.write("---")
            st.write("üìä Resumen de procesamiento:")
            st.write(f"- Total archivos: {len(pdf_files)}")
            st.write(f"- Procesados correctamente: {len(successful_files)}")
            st.write(f"- Fallidos: {len(failed_files)}")
            
            if failed_files:
                st.error("‚ùå Archivos que no se pudieron procesar:")
                for file, error in failed_files:
                    st.write(f"- {file}: {error}")

            if not documents:
                st.warning("‚ö†Ô∏è No se pudo extraer contenido de ning√∫n PDF.")
                return None

            texts = self.text_splitter.split_documents(documents)
            vectorstore = FAISS.from_documents(texts, self.embeddings)
            vectorstore.save_local(self.index_directory)
            
            st.success(f"‚úÖ Vector store creado exitosamente con {len(texts)} fragmentos de texto")
            return vectorstore
        
        except Exception as e:
            st.error(f"Error procesando documentos: {str(e)}")
            return None

def setup_retrieval_chain(vector_store):
    """Configura la cadena de recuperaci√≥n para consultas"""
    memory = ConversationBufferMemory(
        memory_key="chat_history",
        return_messages=True
    )
    
    retrieval_chain = ConversationalRetrievalChain.from_llm(
        llm=ChatOpenAI(temperature=0),
        retriever=vector_store.as_retriever(search_kwargs={"k": 3}),
        memory=memory,
        return_source_documents=True
    )
    
    return retrieval_chain

class StreamHandler(BaseCallbackHandler):
    def __init__(self, container):
        self.container = container
        self.text = ""
        
    def on_llm_new_token(self, token: str, **kwargs) -> None:
        self.text += token
        self.container.markdown(self.text)

def get_municipal_context(vector_store, query):
    """
    Obtiene el contexto relevante de los documentos para una consulta.
    """
    similar_docs = vector_store.similarity_search(query, k=3)
    context_list = []
    
    for doc in similar_docs:
        # Extraer informaci√≥n b√°sica del documento
        content = doc.page_content
        source = doc.metadata.get('source', 'Documento sin especificar')
        
        # Extraer datos cuantitativos
        numbers = re.findall(r'(\d+(?:\.\d+)?(?:%|\s+(?:habitantes|personas|viviendas)))', content)
        metrics = numbers[:3] if numbers else []
        
        # Extraer referencias a pol√≠ticas, programas o indicadores
        refs = re.findall(r'(?:Plan|Programa|Proyecto|Meta|Indicador)[\s:].*?(?=\n|$)', content)
        
        context_list.append({
            'source': source,
            'content': content[:300],  # Limitar longitud del contenido
            'metrics': metrics,
            'refs': refs[:3]  # Limitar n√∫mero de referencias
        })
    
    return context_list

SYSTEM_PROMPT = """
Eres BogotAI, un asistente especializado para apoyar al equipo de la Alcald√≠a de Bogot√°. Tu funci√≥n es proporcionar informaci√≥n precisa y an√°lisis basados en datos para apoyar la toma de decisiones.

## Tipos de Consultas y Respuestas

1. CONSULTAS SOBRE INDICADORES
Cuando te pregunten sobre indicadores espec√≠ficos (ej: seguridad, movilidad, pobreza):
- Proporciona el dato m√°s reciente disponible
- Muestra la evoluci√≥n hist√≥rica si est√° disponible
- Compara con otras localidades o ciudades relevantes
- Identifica tendencias clave y puntos de atenci√≥n

Ejemplo:
"¬øC√≥mo ha evolucionado la pobreza en Bogot√°?"
```
Datos actuales: [√∫ltimo dato disponible]
Tendencia: [an√°lisis de evoluci√≥n]
Comparaci√≥n territorial: [diferencias por localidad]
Puntos clave: [factores relevantes]
```

2. CONSULTAS SOBRE POL√çTICAS ESPEC√çFICAS
Para preguntas sobre programas o pol√≠ticas concretas:
- Resume el objetivo y alcance
- Indica el estado actual de implementaci√≥n
- Se√±ala los principales logros y desaf√≠os
- Sugiere oportunidades de mejora basadas en evidencia

3. CONSULTAS DE CONTEXTUALIZACI√ìN
Cuando necesiten entender el contexto de un problema:
- Proporciona antecedentes relevantes
- Explica factores causales
- Describe intentos previos de soluci√≥n
- Menciona experiencias exitosas de otras ciudades

4. CONSULTAS DE IMPLEMENTACI√ìN
Para preguntas sobre ejecuci√≥n de programas:
- Detalla pasos concretos y cronograma
- Identifica recursos necesarios
- Anticipa posibles obst√°culos
- Sugiere indicadores de seguimiento

## Uso del Contexto

- Al citar datos o informaci√≥n, especifica siempre la fuente y fecha
- Prioriza la informaci√≥n m√°s reciente disponible
- Usa el contexto local de Bogot√° cuando est√© disponible
- Indica claramente cuando la informaci√≥n est√© desactualizada o sea limitada

## Principios de Respuesta

1. CLARIDAD Y PRECISI√ìN
- Usa lenguaje claro y directo
- Estructura las respuestas en secciones
- Prioriza informaci√≥n accionable
- Destaca los puntos m√°s importantes

2. ENFOQUE EN DATOS
- Basa las recomendaciones en evidencia
- Presenta datos de forma clara y contextualizada
- Se√±ala limitaciones o vac√≠os en los datos
- Sugiere m√©tricas de seguimiento

3. ORIENTACI√ìN PR√ÅCTICA
- Enf√≥cate en soluciones viables
- Considera restricciones presupuestales
- Ten en cuenta la capacidad institucional
- Prioriza acciones de alto impacto

## Temas Prioritarios

1. SEGURIDAD Y CONVIVENCIA
- Tasas de criminalidad
- Percepci√≥n de seguridad
- Programas de prevenci√≥n
- Coordinaci√≥n institucional

2. MOVILIDAD
- Estado de obras en curso
- Indicadores de transporte p√∫blico
- Congesti√≥n vehicular
- Infraestructura de transporte

3. EQUIDAD SOCIAL
- Indicadores de pobreza
- Acceso a servicios
- Programas sociales
- Brechas territoriales

4. GESTI√ìN P√öBLICA
- Ejecuci√≥n presupuestal
- Indicadores de servicio
- Modernizaci√≥n administrativa
- Participaci√≥n ciudadana

## Formato de Respuesta

Para cada consulta, estructura tu respuesta as√≠:

1. RESUMEN EJECUTIVO
- Puntos clave
- Datos relevantes
- Principales hallazgos

2. AN√ÅLISIS DETALLADO
- Contexto
- Tendencias
- Factores causales
- Impactos

3. RECOMENDACIONES
- Acciones inmediatas
- Estrategias de mediano plazo
- Consideraciones de implementaci√≥n

4. SEGUIMIENTO
- Indicadores clave
- Puntos de control
- Pr√≥ximos pasos

## Advertencias y Limitaciones

- Indica claramente cuando la informaci√≥n est√© desactualizada
- Se√±ala √°reas donde falten datos o evidencia
- Especifica cuando las recomendaciones sean preliminares
- Sugiere la consulta con expertos cuando sea necesaria  
- Si no tienes informacion sobre algo en especifico, responde con que no tienes suficiente informacion sobre eso o neesitas mas informacion sobre eso. 
- SIEMPRE RESPONDE EN ESPA√ëOL  
- Si te saludan "Hola BogotAI" o preguntan quien eres respondeles de manera concisas diciendo quien ers y en que puedes ayudarlos. 

Recuerda: Tu rol es apoyar la toma de decisiones proporcionando informaci√≥n y an√°lisis basado en evidencia, no tomar las decisiones finales.
"""

def detect_response_format(prompt):
    """
    Detecta si una consulta requiere una respuesta estructurada o simple.
    Retorna un string con el formato detectado.
    
    Parameters:
    prompt (str): La consulta del usuario
    
    Returns:
    str: 'STRUCTURED' o 'SIMPLE'
    """
    prompt = prompt.lower()
    
    # Indicadores de consulta estructurada
    structured_indicators = [
        # An√°lisis y comparaci√≥n
        'analizar', 'comparar', 'evaluar', 'diferencia',
        'evoluci√≥n', 'tendencia', 'impacto',
        
        # Planeaci√≥n y gesti√≥n
        'plan', 'programa', 'proyecto', 'estrategia',
        'pol√≠tica', 'presupuesto', 'implementaci√≥n',
        
        # Territorio y datos
        'localidad', 'territorio', 'zona', 'sector',
        'estad√≠stica', 'indicador', 'porcentaje', 'densidad',
        
        # Tem√°ticas complejas
        'seguridad', 'movilidad', 'pobreza', 'desarrollo',
        'infraestructura', 'ambiente', 'educaci√≥n', 'salud'
    ]
    
    # Indicadores de consulta simple
    simple_indicators = [
        # Preguntas b√°sicas
        'qu√© es', 'que es', 'd√≥nde', 'donde', 'cu√°ndo', 'cuando',
        'qui√©n', 'quien', 'cu√°l', 'cual', 'cu√°nto', 'cuanto',
        
        # Definiciones y datos puntuales
        'significa', 'define', 'explica', 'valor', 'dato',
        'horario', 'direcci√≥n', 'tel√©fono', 'requisito'
    ]
    
    # Criterios de complejidad
    is_complex = (
        len(prompt.split()) > 15 or              # Longitud de la pregunta
        prompt.count('?') > 1 or                 # M√∫ltiples preguntas
        prompt.count(',') > 1 or                 # M√∫ltiples elementos
        prompt.count(' y ') > 1 or              # M√∫ltiples conceptos
        any(ind in prompt for ind in structured_indicators)  # Indicadores de estructura
    )
    
    # Criterios de simplicidad
    is_simple = (
        any(ind in prompt for ind in simple_indicators) and  # Indicadores simples
        not is_complex                                       # No es compleja
    )
    
    return 'SIMPLE' if is_simple else 'STRUCTURED'

def format_structured_response(query_type, context):
    """
    Formatea una respuesta estructurada seleccionando secciones relevantes
    seg√∫n el tipo de consulta.
    """
    # Definir todas las secciones posibles con sus emojis y contenido
    sections = {
        'resumen': ('üìã', 'RESUMEN EJECUTIVO', ['S√≠ntesis del tema', 'Puntos clave', 'Contexto general']),
        'objetivos': ('üéØ', 'OBJETIVOS Y ALCANCE', ['Objetivos principales', 'Poblaci√≥n objetivo', 'Cobertura']),
        'indicadores': ('üìä', 'INDICADORES CLAVE', ['Estado actual', 'Evoluci√≥n', 'Metas']),
        'territorial': ('üìç', 'AN√ÅLISIS TERRITORIAL', ['Impacto por localidades', 'Zonas cr√≠ticas', 'Distribuci√≥n']),
        'recursos': ('üí∞', 'RECURSOS Y PRESUPUESTO', ['Presupuesto', 'Fuentes', 'Ejecuci√≥n']),
        'implementacion': ('üìÖ', 'IMPLEMENTACI√ìN', ['Estado actual', 'Cronograma', 'Hitos']),
        'recomendaciones': ('‚ö°', 'RECOMENDACIONES', ['Acciones sugeridas', 'Prioridades', 'Seguimiento']),
        'normativo': ('‚öñÔ∏è', 'MARCO NORMATIVO', ['Normativa aplicable', 'Competencias', 'Requisitos']),
        'actores': ('üë•', 'ACTORES CLAVE', ['Responsables', 'Aliados', 'Grupos de inter√©s'])
    }

    # Mapear tipos de consulta a secciones relevantes
    type_sections = {
        'SEGURIDAD_MOVILIDAD': ['resumen', 'indicadores', 'territorial', 'implementacion', 'recomendaciones'],
        'EQUIDAD_SOCIAL': ['resumen', 'objetivos', 'indicadores', 'recursos', 'recomendaciones'],
        'PLANEACION_TERRITORIO': ['resumen', 'objetivos', 'territorial', 'implementacion', 'normativo'],
        'GESTION_RECURSOS': ['resumen', 'recursos', 'indicadores', 'implementacion', 'actores'],
        'AMBIENTE_DESARROLLO': ['resumen', 'objetivos', 'territorial', 'implementacion', 'recomendaciones'],
        'SERVICIOS_CIUDADANOS': ['resumen', 'objetivos', 'normativo', 'actores', 'recomendaciones']
    }

    # Obtener secciones relevantes para el tipo de consulta
    relevant_sections = type_sections.get(query_type, ['resumen', 'recomendaciones'])

    # Construir el prompt
    prompt_parts = [f"Tipo de consulta: {query_type}\n"]
    
    # Agregar contexto si existe
    if context:
        prompt_parts.append(f"Contexto relevante:\n{context}\n")

    # Agregar secciones relevantes
    for section_key in relevant_sections:
        if section_key in sections:
            emoji, title, bullets = sections[section_key]
            prompt_parts.append(f"""
{emoji} {title}:
‚Ä¢ {bullets[0]}
‚Ä¢ {bullets[1]}
‚Ä¢ {bullets[2]}
""")

    return "\n".join(prompt_parts)

def format_simple_response(query_type, context):
    """Genera un prompt para respuesta simple"""
    return f"""
    Tipo de consulta: {query_type}
    
    Contexto municipal relevante:
    {context}
    
    Proporciona una respuesta clara y concisa en formato de p√°rrafo, sin usar vi√±etas ni secciones.
    La respuesta debe ser directa y enfocada en responder la pregunta espec√≠fica.
    """

def format_municipal_context(context_list):
    """
    Formatea el contexto municipal para presentaci√≥n.
    """
    if not isinstance(context_list, list):
        return "No se encontr√≥ contexto relevante."
        
    formatted_parts = []
    
    for item in context_list:
        # Formatear referencias
        refs = item.get('refs', [])
        refs_text = "\n‚Ä¢ ".join(refs) if refs else "No hay referencias espec√≠ficas"
        
        # Formatear m√©tricas
        metrics = item.get('metrics', [])
        metrics_text = "\n‚Ä¢ ".join(metrics) if metrics else "No hay datos cuantitativos espec√≠ficos"
        
        section = f"""
üìö Fuente: {item['source']}

üìä Datos clave:
‚Ä¢ {metrics_text}

üìã Referencias:
‚Ä¢ {refs_text}

üí° Contexto relevante:
{item['content']}"""
        formatted_parts.append(section)
    
    return "\n---\n".join(formatted_parts)

def detect_query_type(prompt):
    """
    Detecta el tipo de consulta basado en los ejes principales del Plan de 
    Desarrollo de Bogot√° y prioridades de la administraci√≥n.
    
    Parameters:
    prompt (str): Consulta del usuario
    
    Returns:
    tuple: (tipo_principal, subtipo, score)
    """
    prompt = prompt.lower()
    
    keywords = {
        'SEGURIDAD_MOVILIDAD': [
            # Seguridad
            'seguridad', 'convivencia', 'delito', 'crimen', 'polic√≠a',
            'vigilancia', 'prevenci√≥n', 'violencia', 'hurto',
            # Movilidad
            'transporte', 'metro', 'transmilenio', 'ciclov√≠a', 'tr√°fico',
            'congesti√≥n', 'obras viales', 'infraestructura vial', 'peatones'
        ],
        
        'EQUIDAD_SOCIAL': [
            # Pobreza y desigualdad
            'pobreza', 'vulnerabilidad', 'inequidad', 'brecha social',
            'transferencias', 'subsidios', 'ayudas', 'inclusi√≥n',
            # Servicios sociales
            'educaci√≥n', 'salud', 'vivienda', 'alimentaci√≥n', 'cuidado',
            'primera infancia', 'adulto mayor', 'discapacidad', 'g√©nero'
        ],
        
        'PLANEACION_TERRITORIO': [
            # Planeaci√≥n
            'plan de desarrollo', 'pot', 'ordenamiento', 'planeaci√≥n',
            'estrategia', 'proyecto', 'programa', 'pol√≠tica p√∫blica',
            # Territorio
            'localidad', 'upz', 'territorio', 'densidad', 'uso del suelo',
            'espacio p√∫blico', 'equipamientos', 'regi√≥n metropolitana'
        ],
        
        'GESTION_RECURSOS': [
            # Gesti√≥n p√∫blica
            'presupuesto', 'inversi√≥n', 'recursos', 'contrataci√≥n',
            'ejecuci√≥n', 'gesti√≥n', 'administrativo', 'modernizaci√≥n',
            # Control
            'seguimiento', 'indicadores', 'evaluaci√≥n', 'metas',
            'transparencia', 'rendici√≥n', 'control', 'auditor√≠a'
        ],
        
        'AMBIENTE_DESARROLLO': [
            # Ambiente
            'ambiente', 'sostenibilidad', 'cambio clim√°tico', 'residuos',
            'reciclaje', 'contaminaci√≥n', 'aire', 'agua', 'verde',
            # Desarrollo econ√≥mico
            'econom√≠a', 'emprendimiento', 'empleo', 'productividad',
            'innovaci√≥n', 'tecnolog√≠a', 'competitividad', 'mipymes'
        ],
        
        'SERVICIOS_CIUDADANOS': [
            # Tr√°mites
            'tr√°mite', 'servicio', 'procedimiento', 'requisitos',
            'documentos', 'solicitud', 'atenci√≥n', 'ventanilla',
            # Participaci√≥n
            'participaci√≥n', 'consulta', 'ciudadan√≠a', 'comunidad',
            'socializaci√≥n', 'encuentro', 'di√°logo', 'concertaci√≥n'
        ]
    }
    
    prompt_lower = prompt.lower()
    for category, terms in keywords.items():
        if any(term in prompt_lower for term in terms):
            return category
    return 'GENERAL'

def format_context_string(context_list):
    """
    Formatea la lista de contextos en un string estructurado.
    """
    if not context_list:
        return "No se encontr√≥ contexto relevante."
        
    formatted_parts = []
    
    for item in context_list:
        section = f"""
üìö Fuente: {item['source']}

üìä Datos relevantes:
{format_metrics(item.get('metrics', []))}

üìã Referencias:
{format_references(item.get('refs', []))}

üí° Contexto:
{item['content']}"""
        formatted_parts.append(section)
    
    return "\n---\n".join(formatted_parts)

def format_metrics(metrics):
    if not metrics:
        return "‚Ä¢ No hay datos cuantitativos espec√≠ficos"
    return "\n".join(f"‚Ä¢ {metric}" for metric in metrics)

def format_references(refs):
    if not refs:
        return "‚Ä¢ No hay referencias espec√≠ficas"
    return "\n".join(f"‚Ä¢ {ref}" for ref in refs)

def get_chat_response(prompt, vector_store, temperature=0.3):
    """Genera respuesta considerando el contexto municipal y el formato apropiado"""
    try:
        response_placeholder = st.empty()
        stream_handler = StreamHandler(response_placeholder)
        
        # 1. Detectar tipo de consulta
        query_type = detect_query_type(prompt)
        
        # 2. Obtener y formatear contexto
        context_items = get_municipal_context(vector_store, prompt)
        formatted_context = format_context_string(context_items)
        
        # 3. Construir prompt mejorado
        enhanced_prompt = f"""
Tipo de consulta: {query_type}

Contexto relevante:
{formatted_context}

Por favor proporciona una respuesta que:
1. Use la informaci√≥n del contexto proporcionado
2. Cite las fuentes espec√≠ficas cuando sea posible
3. Destaque datos cuantitativos relevantes
4. Proporcione recomendaciones basadas en evidencia
"""
        
        # 4. Generar respuesta
        chat_model = ChatOpenAI(
            model="gpt-4",
            temperature=temperature,
            api_key=API_KEY,
            streaming=True,
            callbacks=[stream_handler]
        )
        
        messages = [
            SystemMessage(content=SYSTEM_PROMPT),
            HumanMessage(content=f"{prompt}\n\n{enhanced_prompt}")
        ]
        
        response = chat_model.invoke(messages)
        return stream_handler.text
            
    except Exception as e:
        st.error(f"Error generando respuesta: {str(e)}")
        return "Lo siento, ocurri√≥ un error al procesar su solicitud."
def main():
    processor = MunicipalDocumentProcessor()
    
    if os.path.exists(os.path.join("faiss_index", "index.faiss")):
        vector_store = processor.load_vector_store()
    else:
        st.warning("Procesando documentos municipales por primera vez...")
        vector_store = processor.process_documents()
    
    if vector_store is None:
        st.error("No se pudo inicializar la base de conocimientos")
        st.stop()

    st.write(logo, unsafe_allow_html=True)
    st.title("BogotAI", anchor=False)
    st.markdown("##### Asistente para la toma de decisiones de pol√≠tica p√∫blica")
    
    if "messages" not in st.session_state:
        st.session_state.messages = []

    with st.sidebar:
        st.markdown("""
        ## Sistema de Gesti√≥n P√∫blica Bogot√°
        
        **Tipos de consultas:**
        - Planificaci√≥n y dise√±o de Pol√≠ticas P√∫blicas 
        - An√°lisis de problemas sociales 
        - Evaluaci√≥n de escenarios 
        - Identificaci√≥n de patrones y tendencias 
        """)
        
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    if prompt := st.chat_input("¬øEn qu√© puedo ayudarte?"):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user", avatar="üë§"):
            st.markdown(prompt)
        
        with st.chat_message("assistant"):
            response = get_chat_response(prompt, vector_store)
            st.session_state.messages.append({"role": "assistant", "content": response})

if __name__ == "__main__":
    main()