import pandas as pd
import streamlit as st
import os
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain.schema import HumanMessage, SystemMessage
from langchain.callbacks.base import BaseCallbackHandler
from html_template import logo
from langchain.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.chains import ConversationalRetrievalChain
from langchain.memory import ConversationBufferMemory
import re

# Load environment variables
load_dotenv()

# Get API key from environment variables
API_KEY = os.getenv("OPENAI_API_KEY")
if API_KEY is None:
    st.error("Error: OPENAI_API_KEY not found in environment variables")
    st.stop()
    
st.set_page_config(page_title="BogoTIA", layout="centered")

class MunicipalDocumentProcessor:
    def __init__(self, pdf_directory="data", index_directory="faiss_index"):
        self.pdf_directory = pdf_directory
        self.index_directory = index_directory
        self.embeddings = OpenAIEmbeddings()
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200,
            length_function=len
        )
        
        os.makedirs(self.pdf_directory, exist_ok=True)
        os.makedirs(self.index_directory, exist_ok=True)

    def load_vector_store(self):
        """Carga el vector store existente"""
        index_path = os.path.join(self.index_directory, "index.faiss")
        try:
            if os.path.exists(index_path):
                return FAISS.load_local(
                    self.index_directory, 
                    self.embeddings,
                    allow_dangerous_deserialization=True
                )
            return None
        except Exception as e:
            st.error(f"Error cargando vector store: {str(e)}")
            return None

    def process_documents(self):
        """Procesa los documentos PDF y crea el vector store"""
        try:
            pdf_files = [f for f in os.listdir(self.pdf_directory) if f.endswith('.pdf')]
            if not pdf_files:
                st.warning("No se encontraron archivos PDF en el directorio data.")
                return None

            documents = []
            successful_files = []
            failed_files = []
            
            for pdf_file in pdf_files:
                try:
                    file_path = os.path.join(self.pdf_directory, pdf_file)
                    
                    with open(file_path, 'rb') as file:
                        header = file.read(5)
                        if header != b'%PDF-':
                            failed_files.append((pdf_file, "Encabezado PDF inv√°lido"))
                            continue
                    
                    loader = PyPDFLoader(file_path)
                    doc_pages = loader.load()
                    
                    if doc_pages:
                        documents.extend(doc_pages)
                        successful_files.append(pdf_file)
                        st.success(f"‚úÖ Procesado exitosamente: {pdf_file} ({len(doc_pages)} p√°ginas)")
                    else:
                        failed_files.append((pdf_file, "No se pudo extraer contenido"))
                
                except Exception as e:
                    failed_files.append((pdf_file, str(e)))
                    continue

            st.write("---")
            st.write("üìä Resumen de procesamiento:")
            st.write(f"- Total archivos: {len(pdf_files)}")
            st.write(f"- Procesados correctamente: {len(successful_files)}")
            st.write(f"- Fallidos: {len(failed_files)}")
            
            if failed_files:
                st.error("‚ùå Archivos que no se pudieron procesar:")
                for file, error in failed_files:
                    st.write(f"- {file}: {error}")

            if not documents:
                st.warning("‚ö†Ô∏è No se pudo extraer contenido de ning√∫n PDF.")
                return None

            texts = self.text_splitter.split_documents(documents)
            vectorstore = FAISS.from_documents(texts, self.embeddings)
            vectorstore.save_local(self.index_directory)
            
            st.success(f"‚úÖ Vector store creado exitosamente con {len(texts)} fragmentos de texto")
            return vectorstore
        
        except Exception as e:
            st.error(f"Error procesando documentos: {str(e)}")
            return None

def setup_retrieval_chain(vector_store):
    """Configura la cadena de recuperaci√≥n para consultas"""
    memory = ConversationBufferMemory(
        memory_key="chat_history",
        return_messages=True
    )
    
    retrieval_chain = ConversationalRetrievalChain.from_llm(
        llm=ChatOpenAI(temperature=0),
        retriever=vector_store.as_retriever(search_kwargs={"k": 3}),
        memory=memory,
        return_source_documents=True
    )
    
    return retrieval_chain

class StreamHandler(BaseCallbackHandler):
    def __init__(self, container):
        self.container = container
        self.text = ""
        
    def on_llm_new_token(self, token: str, **kwargs) -> None:
        self.text += token
        self.container.markdown(self.text)

def get_municipal_context(vector_store, query):
    """Obtiene el contexto municipal relevante para una consulta"""
    similar_docs = vector_store.similarity_search(query, k=5)
    context = []
    
    for doc in similar_docs:
        content = doc.page_content
        source = doc.metadata.get('source', 'Documento desconocido')
        page = doc.metadata.get('page', 'N/A')
        
        # Extraer referencias espec√≠ficas
        refs = re.findall(r'(?:Acuerdo|Decreto|Resoluci√≥n|Plan)\s+\d+[^\n]*', content)
        
        context.append({
            'source': f"{source} (P√°g. {page})",
            'content': content,
            'refs': refs
        })
    
    return context

SYSTEM_PROMPT = """
Eres BogotAI, un asistente especializado para apoyar al equipo de la Alcald√≠a de Bogot√°. Tu funci√≥n es proporcionar informaci√≥n precisa y an√°lisis basados en datos para apoyar la toma de decisiones.

## Tipos de Consultas y Respuestas

1. CONSULTAS SOBRE INDICADORES
Cuando te pregunten sobre indicadores espec√≠ficos (ej: seguridad, movilidad, pobreza):
- Proporciona el dato m√°s reciente disponible
- Muestra la evoluci√≥n hist√≥rica si est√° disponible
- Compara con otras localidades o ciudades relevantes
- Identifica tendencias clave y puntos de atenci√≥n

Ejemplo:
"¬øC√≥mo ha evolucionado la pobreza en Bogot√°?"
```
Datos actuales: [√∫ltimo dato disponible]
Tendencia: [an√°lisis de evoluci√≥n]
Comparaci√≥n territorial: [diferencias por localidad]
Puntos clave: [factores relevantes]
```

2. CONSULTAS SOBRE POL√çTICAS ESPEC√çFICAS
Para preguntas sobre programas o pol√≠ticas concretas:
- Resume el objetivo y alcance
- Indica el estado actual de implementaci√≥n
- Se√±ala los principales logros y desaf√≠os
- Sugiere oportunidades de mejora basadas en evidencia

3. CONSULTAS DE CONTEXTUALIZACI√ìN
Cuando necesiten entender el contexto de un problema:
- Proporciona antecedentes relevantes
- Explica factores causales
- Describe intentos previos de soluci√≥n
- Menciona experiencias exitosas de otras ciudades

4. CONSULTAS DE IMPLEMENTACI√ìN
Para preguntas sobre ejecuci√≥n de programas:
- Detalla pasos concretos y cronograma
- Identifica recursos necesarios
- Anticipa posibles obst√°culos
- Sugiere indicadores de seguimiento

## Uso del Contexto

- Al citar datos o informaci√≥n, especifica siempre la fuente y fecha
- Prioriza la informaci√≥n m√°s reciente disponible
- Usa el contexto local de Bogot√° cuando est√© disponible
- Indica claramente cuando la informaci√≥n est√© desactualizada o sea limitada

## Principios de Respuesta

1. CLARIDAD Y PRECISI√ìN
- Usa lenguaje claro y directo
- Estructura las respuestas en secciones
- Prioriza informaci√≥n accionable
- Destaca los puntos m√°s importantes

2. ENFOQUE EN DATOS
- Basa las recomendaciones en evidencia
- Presenta datos de forma clara y contextualizada
- Se√±ala limitaciones o vac√≠os en los datos
- Sugiere m√©tricas de seguimiento

3. ORIENTACI√ìN PR√ÅCTICA
- Enf√≥cate en soluciones viables
- Considera restricciones presupuestales
- Ten en cuenta la capacidad institucional
- Prioriza acciones de alto impacto

## Temas Prioritarios

1. SEGURIDAD Y CONVIVENCIA
- Tasas de criminalidad
- Percepci√≥n de seguridad
- Programas de prevenci√≥n
- Coordinaci√≥n institucional

2. MOVILIDAD
- Estado de obras en curso
- Indicadores de transporte p√∫blico
- Congesti√≥n vehicular
- Infraestructura de transporte

3. EQUIDAD SOCIAL
- Indicadores de pobreza
- Acceso a servicios
- Programas sociales
- Brechas territoriales

4. GESTI√ìN P√öBLICA
- Ejecuci√≥n presupuestal
- Indicadores de servicio
- Modernizaci√≥n administrativa
- Participaci√≥n ciudadana

## Formato de Respuesta

Para cada consulta, estructura tu respuesta as√≠:

1. RESUMEN EJECUTIVO
- Puntos clave
- Datos relevantes
- Principales hallazgos

2. AN√ÅLISIS DETALLADO
- Contexto
- Tendencias
- Factores causales
- Impactos

3. RECOMENDACIONES
- Acciones inmediatas
- Estrategias de mediano plazo
- Consideraciones de implementaci√≥n

4. SEGUIMIENTO
- Indicadores clave
- Puntos de control
- Pr√≥ximos pasos

## Advertencias y Limitaciones

- Indica claramente cuando la informaci√≥n est√© desactualizada
- Se√±ala √°reas donde falten datos o evidencia
- Especifica cuando las recomendaciones sean preliminares
- Sugiere la consulta con expertos cuando sea necesaria  
- Si no tienes informacion sobre algo en especifico, responde con que no tienes suficiente informacion sobre eso o neesitas mas informacion sobre eso. 
- SIEMPRE RESPONDE EN ESPA√ëOL 

Recuerda: Tu rol es apoyar la toma de decisiones proporcionando informaci√≥n y an√°lisis basado en evidencia, no tomar las decisiones finales.
"""

def detect_response_format(prompt):
    """Detecta el formato de respuesta m√°s apropiado basado en la consulta"""
    # Keywords que sugieren una respuesta estructurada
    structured_keywords = [
        {
        'ANALISIS_INDICADORES': [
            'densidad', 'poblaci√≥n', 'indicador', 'tasa', 'porcentaje', 
            'estad√≠stica', 'medici√≥n', 'cifras', 'datos', 'evoluci√≥n',
            'tendencia', 'comparaci√≥n', 'crecimiento', 'disminuci√≥n'
        ],
        
        'ANALISIS_TERRITORIAL': [
            'localidad', 'upz', 'barrio', 'zona', 'territorio',
            'rural', 'urbano', 'regi√≥n', 'metropolitana', 'distrito',
            'centro poblado', '√°rea', 'sector', 'comuna'
        ],
        
        'PLAN_GOBIERNO': [
            'programa', 'proyecto', 'iniciativa', 'pol√≠tica', 'plan',
            'estrategia', 'meta', 'objetivo', 'presupuesto', 'inversi√≥n',
            'implementaci√≥n', 'ejecuci√≥n', 'seguimiento', 'evaluaci√≥n'
        ],
        
        'SERVICIOS_CIUDADANOS': [
            'tr√°mite', 'servicio', 'atenci√≥n', 'procedimiento', 'requisitos',
            'documentos', 'solicitud', 'petici√≥n', 'reclamo', 'consulta',
            'proceso', 'gesti√≥n'
        ],
        
        'TEMAS_PRIORITARIOS': {
            'seguridad': [
                'crimen', 'delito', 'seguridad', 'convivencia', 'polic√≠a',
                'vigilancia', 'prevenci√≥n', 'hurto', 'violencia'
            ],
            'movilidad': [
                'transporte', 'metro', 'transmilenio', 'v√≠a', 'calle',
                'avenida', 'ciclov√≠a', 'peat√≥n', 'tr√°fico', 'congesti√≥n'
            ],
            'social': [
                'pobreza', 'educaci√≥n', 'salud', 'vivienda', 'empleo',
                'inclusi√≥n', 'equidad', 'vulnerable', 'comunidad'
            ],
            'ambiente': [
                'ambiente', 'contaminaci√≥n', 'residuos', 'reciclaje',
                'verde', 'sostenible', 'clima', 'agua', 'aire'
            ]
        }
    }
    ]
    
    # Keywords que sugieren una respuesta simple
    simple_keywords = [
        # Preguntas b√°sicas de informaci√≥n
        'qu√© es', 'que es',           # Para definiciones
        'd√≥nde', 'donde',             # Para ubicaciones
        'cu√°ndo', 'cuando',           # Para fechas/horarios
        'qui√©n', 'quien',             # Para responsables
        'cu√°l', 'cual',               # Para opciones
        'cu√°nto', 'cuanto',           # Para valores/cantidades
        
        # Consultas de datos puntuales
        'valor',                      # Para cifras espec√≠ficas
        'tasa',                       # Para indicadores simples
        'n√∫mero',                     # Para cantidades
        'porcentaje',                 # Para proporciones
        'dato',                       # Para informaci√≥n puntual
        'cifra',                      # Para estad√≠sticas simples
        
        # Ubicaci√≥n y acceso
        'direcci√≥n',                  # Para localizaci√≥n
        'horario',                    # Para tiempos de atenci√≥n
        'tel√©fono',                   # Para contacto
        'sede',                       # Para puntos de atenci√≥n
        'punto',                      # Para ubicaciones de servicio
        'oficina',                    # Para lugares administrativos
        
        # Definiciones y conceptos
        'define',                     # Para conceptos
        'significa',                  # Para t√©rminos t√©cnicos
        'explica',                    # Para aclaraciones
        'descripci√≥n',                # Para caracterizaciones breves
        'concepto',                   # Para definiciones formales
        
        # Estados y situaciones
        'estado',                     # Para situaci√≥n actual
        'vigente',                    # Para validez actual
        'disponible',                 # Para disponibilidad
        'abierto',                    # Para estado de servicio
        'activo',                     # Para estado de operaci√≥n
        
        # Informaci√≥n b√°sica de servicios
        'costo',                      # Para valores de servicios
        'tarifa',                     # Para precios
        'requisito',                  # Para requerimientos b√°sicos
        'documento',                  # Para papeles necesarios
        'plazo',                      # Para tiempos l√≠mite
        
        # Consultas de responsabilidad
        'encargado',                  # Para responsables
        'responsable',                # Para asignaci√≥n de tareas
        'autoridad',                  # Para competencia
        'competente',                 # Para jurisdicci√≥n
        'atiende'                     # Para servicio al ciudadano
    ]
    
    prompt_lower = prompt.lower()
    
    # Detectar si la pregunta es compleja por su longitud
    is_complex = len(prompt.split()) > 15
    
    # Detectar si contiene m√∫ltiples preguntas
    has_multiple_questions = prompt.count('?') > 1
    
    # Determinar el formato basado en las condiciones
    if has_multiple_questions or any(keyword in prompt_lower for keyword in structured_keywords):
        return 'STRUCTURED'
    elif any(keyword in prompt_lower for keyword in simple_keywords) and not is_complex:
        return 'SIMPLE'
    else:
        return 'STRUCTURED'

def format_structured_response(query_type, context):
    """
    Genera un prompt para respuesta estructurada adaptado al contexto 
    de la Alcald√≠a de Bogot√°.
    
    Parameters:
    query_type (str): Tipo de consulta (pol√≠tica, indicador, territorial, etc.)
    context (str): Contexto espec√≠fico de la consulta
    
    Returns:
    str: Prompt estructurado para la respuesta
    """
    
    # Definir formatos espec√≠ficos seg√∫n el tipo de consulta
    formats = {
        'politica_publica': """
    Tipo de consulta: {query_type}
    
    üìã RESUMEN EJECUTIVO:
    ‚Ä¢ [S√≠ntesis de la pol√≠tica/programa]
    
    üéØ OBJETIVOS Y ALCANCE:
    ‚Ä¢ [Objetivos principales]
    ‚Ä¢ [Poblaci√≥n objetivo]
    ‚Ä¢ [Cobertura territorial]
    
    üìä INDICADORES CLAVE:
    ‚Ä¢ [M√©tricas de seguimiento]
    ‚Ä¢ [Estado actual]
    ‚Ä¢ [Metas establecidas]
    
    üìç AN√ÅLISIS TERRITORIAL:
    ‚Ä¢ [Impacto por localidades]
    ‚Ä¢ [Brechas identificadas]
    ‚Ä¢ [Priorizaci√≥n territorial]
    
    üí∞ RECURSOS Y PRESUPUESTO:
    ‚Ä¢ [Asignaci√≥n presupuestal]
    ‚Ä¢ [Fuentes de financiaci√≥n]
    ‚Ä¢ [Ejecuci√≥n actual]
    
    üìÖ CRONOGRAMA:
    ‚Ä¢ [Estado de implementaci√≥n]
    ‚Ä¢ [Pr√≥ximos hitos]
    ‚Ä¢ [Fechas clave]
    """,
        
        'indicador_gestion': """
    Tipo de consulta: {query_type}
    
    üìä DATO ACTUAL:
    ‚Ä¢ [Valor m√°s reciente]
    ‚Ä¢ [Fecha de medici√≥n]
    ‚Ä¢ [Fuente del dato]
    
    üìà EVOLUCI√ìN HIST√ìRICA:
    ‚Ä¢ [Tendencia]
    ‚Ä¢ [Variaciones significativas]
    ‚Ä¢ [Comparativo anual]
    
    üó∫Ô∏è AN√ÅLISIS ESPACIAL:
    ‚Ä¢ [Distribuci√≥n por localidades]
    ‚Ä¢ [Zonas cr√≠ticas]
    ‚Ä¢ [Patrones territoriales]
    
    üéØ METAS Y BRECHAS:
    ‚Ä¢ [Objetivo establecido]
    ‚Ä¢ [Brecha actual]
    ‚Ä¢ [Factores cr√≠ticos]
    
    üìã RECOMENDACIONES:
    ‚Ä¢ [Acciones sugeridas]
    ‚Ä¢ [Prioridades]
    ‚Ä¢ [Alertas tempranas]
    """,
        
        'proyecto_territorial': """
    Tipo de consulta: {query_type}
    
    üìç LOCALIZACI√ìN:
    ‚Ä¢ [Ubicaci√≥n espec√≠fica]
    ‚Ä¢ [√Årea de influencia]
    ‚Ä¢ [Poblaci√≥n beneficiada]
    
    üìä DIAGN√ìSTICO:
    ‚Ä¢ [Situaci√≥n actual]
    ‚Ä¢ [Problem√°ticas identificadas]
    ‚Ä¢ [Potencialidades]
    
    üéØ INTERVENCI√ìN:
    ‚Ä¢ [Acciones propuestas]
    ‚Ä¢ [Componentes del proyecto]
    ‚Ä¢ [Articulaci√≥n institucional]
    
    üìÖ IMPLEMENTACI√ìN:
    ‚Ä¢ [Fases del proyecto]
    ‚Ä¢ [Cronograma]
    ‚Ä¢ [Hitos clave]
    
    üí∞ INVERSI√ìN:
    ‚Ä¢ [Presupuesto asignado]
    ‚Ä¢ [Fuentes de recursos]
    ‚Ä¢ [Estado de ejecuci√≥n]
    """
    }
    
    # Seleccionar formato base seg√∫n el tipo de consulta
    base_format = formats.get(query_type, formats['politica_publica'])
    
    # Agregar contexto com√∫n para todas las consultas
    common_context = """
    üîó ALINEACI√ìN PLAN DE DESARROLLO:
    ‚Ä¢ [Eje estrat√©gico]
    ‚Ä¢ [Programa relacionado]
    ‚Ä¢ [Metas asociadas]
    
    ‚öñÔ∏è MARCO NORMATIVO:
    ‚Ä¢ [Normativa aplicable]
    ‚Ä¢ [Competencias]
    ‚Ä¢ [Requisitos legales]
    
    üë• ACTORES CLAVE:
    ‚Ä¢ [Entidades responsables]
    ‚Ä¢ [Aliados estrat√©gicos]
    ‚Ä¢ [Grupos de inter√©s]
    
    ‚ö†Ô∏è ALERTAS Y CONSIDERACIONES:
    ‚Ä¢ [Riesgos identificados]
    ‚Ä¢ [Factores cr√≠ticos]
    ‚Ä¢ [Aspectos a monitorear]
    """
    
    # Construir respuesta final
    full_response = f"""
    {base_format}
    
    {common_context}
    
    Contexto espec√≠fico:
    {context}
    """
    
    return full_response.format(query_type=query_type)

def format_simple_response(query_type, context):
    """Genera un prompt para respuesta simple"""
    return f"""
    Tipo de consulta: {query_type}
    
    Contexto municipal relevante:
    {context}
    
    Proporciona una respuesta clara y concisa en formato de p√°rrafo, sin usar vi√±etas ni secciones.
    La respuesta debe ser directa y enfocada en responder la pregunta espec√≠fica.
    """

def format_municipal_context(context):
    """Formatea el contexto municipal para el prompt"""
    formatted = []
    for item in context:
        refs = '\n'.join(f"‚Ä¢ {ref}" for ref in item['refs']) if item['refs'] else "No se encontraron referencias espec√≠ficas"
        formatted.append(f"""
        üìö Fuente: {item['source']}
        
        üìã Referencias:
        {refs}
        
        üí° Contexto relevante:
        {item['content'][:500]}...
        """)
    return '\n'.join(formatted)

def detect_query_type(prompt):
    """
    Detecta el tipo de consulta basado en los ejes principales del Plan de 
    Desarrollo de Bogot√° y prioridades de la administraci√≥n.
    
    Parameters:
    prompt (str): Consulta del usuario
    
    Returns:
    tuple: (tipo_principal, subtipo, score)
    """
    prompt = prompt.lower()
    
    keywords = {
        'SEGURIDAD_MOVILIDAD': [
            # Seguridad
            'seguridad', 'convivencia', 'delito', 'crimen', 'polic√≠a',
            'vigilancia', 'prevenci√≥n', 'violencia', 'hurto',
            # Movilidad
            'transporte', 'metro', 'transmilenio', 'ciclov√≠a', 'tr√°fico',
            'congesti√≥n', 'obras viales', 'infraestructura vial', 'peatones'
        ],
        
        'EQUIDAD_SOCIAL': [
            # Pobreza y desigualdad
            'pobreza', 'vulnerabilidad', 'inequidad', 'brecha social',
            'transferencias', 'subsidios', 'ayudas', 'inclusi√≥n',
            # Servicios sociales
            'educaci√≥n', 'salud', 'vivienda', 'alimentaci√≥n', 'cuidado',
            'primera infancia', 'adulto mayor', 'discapacidad', 'g√©nero'
        ],
        
        'PLANEACION_TERRITORIO': [
            # Planeaci√≥n
            'plan de desarrollo', 'pot', 'ordenamiento', 'planeaci√≥n',
            'estrategia', 'proyecto', 'programa', 'pol√≠tica p√∫blica',
            # Territorio
            'localidad', 'upz', 'territorio', 'densidad', 'uso del suelo',
            'espacio p√∫blico', 'equipamientos', 'regi√≥n metropolitana'
        ],
        
        'GESTION_RECURSOS': [
            # Gesti√≥n p√∫blica
            'presupuesto', 'inversi√≥n', 'recursos', 'contrataci√≥n',
            'ejecuci√≥n', 'gesti√≥n', 'administrativo', 'modernizaci√≥n',
            # Control
            'seguimiento', 'indicadores', 'evaluaci√≥n', 'metas',
            'transparencia', 'rendici√≥n', 'control', 'auditor√≠a'
        ],
        
        'AMBIENTE_DESARROLLO': [
            # Ambiente
            'ambiente', 'sostenibilidad', 'cambio clim√°tico', 'residuos',
            'reciclaje', 'contaminaci√≥n', 'aire', 'agua', 'verde',
            # Desarrollo econ√≥mico
            'econom√≠a', 'emprendimiento', 'empleo', 'productividad',
            'innovaci√≥n', 'tecnolog√≠a', 'competitividad', 'mipymes'
        ],
        
        'SERVICIOS_CIUDADANOS': [
            # Tr√°mites
            'tr√°mite', 'servicio', 'procedimiento', 'requisitos',
            'documentos', 'solicitud', 'atenci√≥n', 'ventanilla',
            # Participaci√≥n
            'participaci√≥n', 'consulta', 'ciudadan√≠a', 'comunidad',
            'socializaci√≥n', 'encuentro', 'di√°logo', 'concertaci√≥n'
        ]
    }
    
    prompt_lower = prompt.lower()
    for category, terms in keywords.items():
        if any(term in prompt_lower for term in terms):
            return category
    return 'GENERAL'

def get_chat_response(prompt, vector_store, temperature=0.3):
    """Genera respuesta considerando el contexto municipal y el formato apropiado"""
    try:
        response_placeholder = st.empty()
        stream_handler = StreamHandler(response_placeholder)
        
        # Detectar tipo de consulta y formato de respuesta
        query_type = detect_query_type(prompt)
        response_format = detect_response_format(prompt)
        municipal_context = get_municipal_context(vector_store, prompt)
        
        # Seleccionar el formato de prompt seg√∫n el tipo de respuesta
        if response_format == 'STRUCTURED':
            enhanced_prompt = format_structured_response(
                query_type, 
                format_municipal_context(municipal_context)
            )
        else:
            enhanced_prompt = format_simple_response(
                query_type, 
                format_municipal_context(municipal_context)
            )
        
        # Ajustar la temperatura seg√∫n el formato
        # Menor temperatura para respuestas estructuradas, mayor para respuestas simples
        adjusted_temperature = 0.3 if response_format == 'STRUCTURED' else 0.7
        
        chat_model = ChatOpenAI(
            model="gpt-4o",
            temperature=adjusted_temperature,
            api_key=API_KEY,
            streaming=True,
            callbacks=[stream_handler]
        )
        
        messages = [
            SystemMessage(content=SYSTEM_PROMPT),
            HumanMessage(content=f"{prompt}\n\n{enhanced_prompt}")
        ]
        
        response = chat_model.invoke(messages)
        return stream_handler.text
            
    except Exception as e:
        st.error(f"Error generando respuesta: {str(e)}")
        return "Lo siento, ocurri√≥ un error al procesar su solicitud."

def main():
    processor = MunicipalDocumentProcessor()
    
    if os.path.exists(os.path.join("faiss_index", "index.faiss")):
        vector_store = processor.load_vector_store()
    else:
        st.warning("Procesando documentos municipales por primera vez...")
        vector_store = processor.process_documents()
    
    if vector_store is None:
        st.error("No se pudo inicializar la base de conocimientos")
        st.stop()

    st.write(logo, unsafe_allow_html=True)
    st.title("BogoTIA", anchor=False)
    st.markdown("**Asistente virtual para gesti√≥n municipal y administraci√≥n p√∫blica**")
    
    if "messages" not in st.session_state:
        st.session_state.messages = []

    with st.sidebar:
        st.markdown("""
        **Sistema de Gesti√≥n Municipal**
        
        Tipos de consultas:
        - Planes y proyectos
        - Gesti√≥n administrativa
        - Procedimientos internos
        - Control y seguimiento
        """)
        
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    if prompt := st.chat_input("¬øEn qu√© puedo ayudarte?"):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user", avatar="üë§"):
            st.markdown(prompt)
        
        with st.chat_message("assistant"):
            response = get_chat_response(prompt, vector_store)
            st.session_state.messages.append({"role": "assistant", "content": response})

if __name__ == "__main__":
    main()